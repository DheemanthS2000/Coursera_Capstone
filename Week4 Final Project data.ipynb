{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Final Project:- Applied data science capstone\n**Creator: Dheemanth Shenoy**\n***"}, {"metadata": {}, "cell_type": "markdown", "source": "## Data"}, {"metadata": {}, "cell_type": "markdown", "source": "### To solve the problem, we will need the following data:\n1. List of neighbourhoods in Kuala Lumpur. This defines the scope of this project which is confined to the city of Kuala Lumpur, the capital city of the country of Malaysia in South East Asia.\n1. Latitude and longitude coordinates of those neighbourhoods. This is required in order to plot the map and also to get the venue data.\n1. Venue data, particularly data related to shopping malls. We will use this data to perform clustering on the neighbourhoods.\n***"}, {"metadata": {}, "cell_type": "markdown", "source": "## Source and Methods "}, {"metadata": {}, "cell_type": "markdown", "source": "This wikipedia page ( __[ Page link ](https://en.wikipedia.org/wiki/Category:Suburbs_in_Kuala_Lumpur)__ ) contains a list of neighbourhoods in Kuala Lumpur, with a total of 70 neighbourhoods. We will use web scraping techniques to extract the data from the Wikipedia page, with the help of Python requests and beautifulsoup packages. Then we will get the geographical coordinates of the neighbourhoods using Python Geocoder package which will give us the latitude and longitude coordinates of the neighbourhoods.After that, we will use Foursquare API to get the venue data for those neighbourhoods.Foursquare has one of the largest database of 105+ million places and is used by over 125,000 developers. Foursquare API will provide many categories of the venue data, we are particularly interested in the Shopping Mall category in order to help us to solve the business problem put forward. This is a project that will make use of many data science skills, from web scraping (Wikipedia), working with API (Foursquare), data cleaning, data wrangling, to machine learning (K-means clustering) and map visualization (Folium). In the next section, we will present the Methodology section where we will discuss the steps taken in this project, the data analysis that we did and the machine learning technique that was used. \n<br>Firstly, we need to get the list of neighbourhoods in the city of Kuala Lumpur. Fortunately, the list is \navailable in the Wikipedia page. \nWe will do web scraping using Python requests and beautifulsoup packages to extract the list of \nneighbourhoods data. However, this is just a list of names. We need to get the geographical \ncoordinates in the form of latitude and longitude in order to be able to use Foursquare API. To do so, \nwe will use the wonderful Geocoder package that will allow us to convert address into geographical \ncoordinates in the form of latitude and longitude. After gathering the data, we will populate the data \ninto a pandas DataFrame and then visualize the neighbourhoods in a map using Folium package. This \nallows us to perform a sanity check to make sure that the geographical coordinates data returned by \nGeocoder are correctly plotted in the city of Kuala Lumpur. \n<br>Next, we will use Foursquare API to get the top 100 venues that are within a radius of 2000 meters. \nWe need to register a Foursquare Developer Account in order to obtain the Foursquare ID and \nFoursquare secret key. We then make API calls to Foursquare passing in the geographical \ncoordinates of the neighbourhoods in a Python loop. Foursquare will return the venue data in JSON \nformat and we will extract the venue name, venue category, venue latitude and longitude. With the \ndata, we can check how many venues were returned for each neighbourhood and examine how \nmany unique categories can be curated from all the returned venues. <br>Then, we will analyse each \nneighbourhood by grouping the rows by neighbourhood and taking the mean of the frequency of \noccurrence of each venue category. By doing so, we are also preparing the data for use in clustering. \nSince we are analysing the \u201cShopping Mall\u201d data, we will filter the \u201cShopping Mall\u201d as venue \ncategory for the neighbourhoods. \nLastly, we will perform clustering on the data by using k-means clustering. K-means clustering \nalgorithm identifies k number of centroids, and then allocates every data point to the nearest \ncluster, while keeping the centroids as small as possible. It is one of the simplest and popular \nunsupervised machine learning algorithms and is particularly suited to solve the problem for this \nproject. We will cluster the neighbourhoods into 3 clusters based on their frequency of occurrence \nfor \u201cShopping Mall\u201d. The results will allow us to identify which neighbourhoods have higher \nconcentration of shopping malls while which neighbourhoods have fewer number of shopping malls. \nBased on the occurrence of shopping malls in different neighbourhoods, it will help us to answer the \nquestion as to which neighbourhoods are most suitable to open new shopping malls. \n \n "}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}